{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Data\n",
    "\n",
    "The Main data source was scraped from TripAdvisor, a popular travel review website, using Scrapy. I decided on scraping all hotel/resort reviews from Punta Cana, a Caribbean vacation destination that is rising in popularity. \n",
    "\n",
    "The Scrapy spider crawled and scraped all the data into a JSON format, although the framework allows for item pipelining into a MongoDB database.\n",
    "\n",
    "Please see /src/tripdadvisor_reviews for the Scrapy source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import functools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator Functions\n",
    "from functools import wraps\n",
    "\n",
    "def my_logger(orig_func):\n",
    "    import logging\n",
    "    logging.basicConfig(filename='{}.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.info(\n",
    "            'Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
    "        return orig_func(*args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def my_timer(orig_func):\n",
    "    import time\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args, **kwargs)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def load_all_jsons(directory):\n",
    "    json_files = [pd.read_json(directory+pos_json) for pos_json \n",
    "                  in os.listdir(directory) if pos_json.endswith('.json')]\n",
    "    return functools.reduce(lambda x,y: pd.concat([x,y], ignore_index=True), json_files)\n",
    "\n",
    "def load_or_make(filepath, overwrite='n'):\n",
    "    def decorator(func):\n",
    "        def wraps(*args, **kwargs):\n",
    "            if overwrite == 'y':\n",
    "                ow = input(f'Are you sure you want to overwrite {filepath}? y/n: ')\n",
    "                if (os.path.exists(filepath)) and (ow == 'y'):\n",
    "                    os.remove(filepath)\n",
    "            try:\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "            except Exception:\n",
    "                data = func(*args, **kwargs)\n",
    "                with open(filepath, 'wb') as to_write:\n",
    "                    pickle.dump(data, to_write)\n",
    "            return data\n",
    "        return wraps\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reviews = load_all_jsons(\"../data/raw/\")\n",
    "pc = pd.read_json(\"../data/raw/puntacana.json\")\n",
    "aspen = pd.read_json(\"../data/raw/aspen.json\")\n",
    "bor = pd.read_json(\"../data/raw/boracay.json\")\n",
    "whistler = pd.read_json(\"../data/raw/whistler.json\")\n",
    "gran = pd.read_json(\"../data/raw/grancanaria.json\")\n",
    "playa = pd.read_json(\"../data/raw/playadelcarmen.json\")\n",
    "vienna = pd.read_json(\"../data/raw/vienna.json\")\n",
    "budapest = pd.read_json(\"../data/raw/budapest.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc[\"city\"]=\"Punta Cana\"\n",
    "aspen[\"city\"]=\"Aspen\"\n",
    "bor[\"city\"]=\"Boracay\"\n",
    "whistler[\"city\"]=\"Whistler\"\n",
    "gran[\"city\"]=\"Gran Canaria\"\n",
    "playa[\"city\"]=\"Playa Del Carmen\"\n",
    "vienna[\"city\"]=\"Vienna\"\n",
    "budapest[\"city\"]=\"Budapest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = functools.reduce(lambda x,y: pd.concat([x,y], ignore_index=True), [pc,aspen,bor,whistler,gran,playa,vienna,budapest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = reviews[reviews.stars >= 4]\n",
    "neg = reviews[reviews.stars < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>hotel</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Hands down great family vacation. Estefan√≠a o...</td>\n",
       "      <td>[The Reserve at Paradisus Punta Cana]</td>\n",
       "      <td>5</td>\n",
       "      <td>[Family concierge stay]</td>\n",
       "      <td>Punta Cana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Juan Batistae has got to be the best host/bar...</td>\n",
       "      <td>[Paradisus Punta Cana Resort]</td>\n",
       "      <td>5</td>\n",
       "      <td>[Sunrise bartender]</td>\n",
       "      <td>Punta Cana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[This was our first trip! We went with our fri...</td>\n",
       "      <td>[Dreams Palm Beach Punta Cana]</td>\n",
       "      <td>5</td>\n",
       "      <td>[Overall Excellent Experience!]</td>\n",
       "      <td>Punta Cana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Me and my partner travelled from Glasgow Scot...</td>\n",
       "      <td>[Now Onyx Punta Cana]</td>\n",
       "      <td>5</td>\n",
       "      <td>[Lovely 10 days]</td>\n",
       "      <td>Punta Cana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[We had amazing time with family and friends. ...</td>\n",
       "      <td>[Paradisus Punta Cana Resort]</td>\n",
       "      <td>4</td>\n",
       "      <td>[Amazing spring break vacation‚úåÔ∏èüëåüë®‚Äçüë©‚Äçüëß‚Äçüë¶üòçüòçüëç]</td>\n",
       "      <td>Punta Cana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  [Hands down great family vacation. Estefan√≠a o...   \n",
       "1  [Juan Batistae has got to be the best host/bar...   \n",
       "2  [This was our first trip! We went with our fri...   \n",
       "3  [Me and my partner travelled from Glasgow Scot...   \n",
       "4  [We had amazing time with family and friends. ...   \n",
       "\n",
       "                                   hotel  stars  \\\n",
       "0  [The Reserve at Paradisus Punta Cana]      5   \n",
       "1          [Paradisus Punta Cana Resort]      5   \n",
       "2         [Dreams Palm Beach Punta Cana]      5   \n",
       "3                  [Now Onyx Punta Cana]      5   \n",
       "4          [Paradisus Punta Cana Resort]      4   \n",
       "\n",
       "                                          title        city  \n",
       "0                       [Family concierge stay]  Punta Cana  \n",
       "1                           [Sunrise bartender]  Punta Cana  \n",
       "2               [Overall Excellent Experience!]  Punta Cana  \n",
       "3                              [Lovely 10 days]  Punta Cana  \n",
       "4  [Amazing spring break vacation‚úåÔ∏èüëåüë®‚Äçüë©‚Äçüëß‚Äçüë¶üòçüòçüëç]  Punta Cana  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub Data\n",
    "\n",
    "This project is an NLP project, and therefore scrubbing the data takes on a different path than a supervised learning project. \n",
    "\n",
    "After importing the data, I have to take these steps:\n",
    "\n",
    "1. Clean the data\n",
    "2. Tokenize the data\n",
    "3. Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import wordnet as WN\n",
    "from nltk.corpus import stopwords, words\n",
    "import string\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_en = stopwords.words('english')\n",
    "newStopWords=['punta','cana','vienna','aspen','whistler',\n",
    "              'gran','canaria','budapest','boracay',\n",
    "              'playa', 'del', 'carmen','was','good','great']\n",
    "typeWords=['hostel','hotel','apartment','resort','room']\n",
    "stop_words_en.extend(newStopWords)\n",
    "stop_words_en.extend(typeWords)\n",
    "stop_words_en = set(stop_words_en)\n",
    "english_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuations(text):\n",
    "    text = re.sub(r\"[^a-z0-9(),!.?\\'`]\", \" \", text)\n",
    "    text = re.sub(r\"\\'s\", \"\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"[(),!.?\\'`]\", \"\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"\\s[a-z]{1,2}\\s\",\" \", text)\n",
    "    return text \n",
    "\n",
    "def tokenize_single(row):\n",
    "    return word_tokenize(row)\n",
    "\n",
    "def clean_single(row):\n",
    "    row = row.strip().lower()\n",
    "    return punctuations(row)\n",
    "#     return english_only(row)\n",
    "\n",
    "@my_timer\n",
    "# @load_or_make('../data/interim/preprocessed1_clean.pickle')\n",
    "def clean(df):\n",
    "    \"\"\"\n",
    "        returns dataframe after cleaning the review text\n",
    "        1: lowercase\n",
    "        2: strip any outer whitespace\n",
    "        3: remove or replace punctuations with one space\n",
    "        4: replace multiple spaces in a row with single space\n",
    "    \"\"\"\n",
    "    columns = list(df.columns)\n",
    "    df[\"clean_review\"] =  df[\"content\"].apply(lambda x: ' '.join(x) if len(x)> 0 else '')\n",
    "    df = df.applymap(lambda x: x if not isinstance(x, list) else x[0] if len(x) else '')\n",
    "    df.clean_review = df.clean_review.apply(lambda x: clean_single(x))\n",
    "    df.clean_review = df.clean_review.apply(lambda x: x.translate(str.maketrans('','',string.digits)))\n",
    "    return df[[\"hotel\",\"city\",\"content\",\"clean_review\"]]\n",
    "\n",
    "@my_timer\n",
    "# @load_or_make('../data/interim/preprocessed3_tokens.pickle')\n",
    "def tokenize(df):\n",
    "    df[\"tokens\"] = df[\"clean_review\"].apply(lambda row: tokenize_single(row))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Text:\n",
    "\n",
    "We first do some general cleaning, including:\n",
    "\n",
    "- removing the lists inside the pandas dataframe\n",
    "- lowercase all strings in the review \n",
    "- remove outer whitespaces\n",
    "- remove digits, words 2 or less characters, punctuations\n",
    "- remove non-English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youngjeong/anaconda3/envs/recommender/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean ran in: 8.104113817214966 sec\n"
     ]
    }
   ],
   "source": [
    "pos = clean(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>city</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Reserve at Paradisus Punta Cana</td>\n",
       "      <td>Punta Cana</td>\n",
       "      <td>Hands down great family vacation. Estefan√≠a ou...</td>\n",
       "      <td>hands down great family vacation estefan our f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paradisus Punta Cana Resort</td>\n",
       "      <td>Punta Cana</td>\n",
       "      <td>Juan Batistae has got to be the best host/bart...</td>\n",
       "      <td>juan batistae has got be the best host bartend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dreams Palm Beach Punta Cana</td>\n",
       "      <td>Punta Cana</td>\n",
       "      <td>This was our first trip! We went with our frie...</td>\n",
       "      <td>this was our first trip went with our friends ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now Onyx Punta Cana</td>\n",
       "      <td>Punta Cana</td>\n",
       "      <td>Me and my partner travelled from Glasgow Scotl...</td>\n",
       "      <td>me and partner travelled from glasgow scotland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paradisus Punta Cana Resort</td>\n",
       "      <td>Punta Cana</td>\n",
       "      <td>We had amazing time with family and friends. A...</td>\n",
       "      <td>we had amazing time with family and friends an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hotel        city  \\\n",
       "0  The Reserve at Paradisus Punta Cana  Punta Cana   \n",
       "1          Paradisus Punta Cana Resort  Punta Cana   \n",
       "2         Dreams Palm Beach Punta Cana  Punta Cana   \n",
       "3                  Now Onyx Punta Cana  Punta Cana   \n",
       "4          Paradisus Punta Cana Resort  Punta Cana   \n",
       "\n",
       "                                             content  \\\n",
       "0  Hands down great family vacation. Estefan√≠a ou...   \n",
       "1  Juan Batistae has got to be the best host/bart...   \n",
       "2  This was our first trip! We went with our frie...   \n",
       "3  Me and my partner travelled from Glasgow Scotl...   \n",
       "4  We had amazing time with family and friends. A...   \n",
       "\n",
       "                                        clean_review  \n",
       "0  hands down great family vacation estefan our f...  \n",
       "1  juan batistae has got be the best host bartend...  \n",
       "2  this was our first trip went with our friends ...  \n",
       "3  me and partner travelled from glasgow scotland...  \n",
       "4  we had amazing time with family and friends an...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pos,open(\"../data/interim/reviews_cleaned.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Text:\n",
    "\n",
    "With the cleaned text, I will run NLTK to convert it into tokenized text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize ran in: 35.4605278968811 sec\n"
     ]
    }
   ],
   "source": [
    "pos = tokenize(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pos,open(\"../data/processed/reviews_tokens.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=pickle.load(open(\"../data/processed/reviews_tokens.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Working with Scott's\n",
    "# mixed = reviews.clean_review.to_list()\n",
    "# mixed2 = scott2.recipe.to_list()\n",
    "# mixed2 = [clean_single(row) for row in mixed2]\n",
    "# mixedall = mixed+mixed2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whistler = tokenize(clean(whistler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean ran in: 1.3403558731079102 sec\n",
      "tokenize ran in: 7.933361053466797 sec\n"
     ]
    }
   ],
   "source": [
    "bor = tokenize(clean(bor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "whistler_freq={}\n",
    "bor_freq={}\n",
    "\n",
    "def count_freq(freq,word):\n",
    "    for w in word:\n",
    "        try:\n",
    "            if w not in stop_words_en:\n",
    "                if w in list(freq.keys()):\n",
    "                    freq[w] += 1\n",
    "                else:\n",
    "                    freq[w] = 1\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in bor.tokens:\n",
    "    count_freq(bor,doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in whistler.tokens:\n",
    "    count_freq(whistler_freq,doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwhistler=dict(Counter(whistler_freq).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stay': 2083, 'village': 1880, 'would': 1758, 'location': 1703, 'staff': 1606}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newwhistler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams and Lemmatization\n",
    "\n",
    "After Cleaning and Tokenizing, the next step is to then generate a Document-Term Matrix. I can use either the CountVectorizer or the TF-IDF to vectorize into Document-Term Matrix with stop_words and ngrams included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "vec_choices = {\n",
    "    'cv': CountVectorizer,\n",
    "    'tfidf': TfidfVectorizer,\n",
    "}\n",
    "    \n",
    "@my_timer\n",
    "def vectorize(documents, method='cv'):\n",
    "    vectorizer = vec_choices[method](stop_words = stop_words_en, ngram_range=(1, 1))\n",
    "    doc_word = vectorizer.fit_transform(documents)\n",
    "    return doc_word, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc_cv, cv= vectorize(reviews.clean_review.to_list(), reviews.hotel,'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(doc_cv.toarray(), index=reviews.hotel.to_list(), columns=cv.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(cv, open(\"../results/models/cv.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorize ran in: 5.861459970474243 sec\n"
     ]
    }
   ],
   "source": [
    "doc_tfidf, tfidf = vectorize(pos.clean_review.to_list(), 'tfidf')\n",
    "# doc_tfidf, tfidf = vectorize(reviews.clean_review.to_list(), reviews.hotel,'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open(\"../results/models/tfidf.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model & Interpret Data\n",
    "\n",
    "I use some of the dimensionality reduction techniques here, specifically Topic Modelling. The three that are used here:\n",
    "\n",
    "- Non-negative Matrix factorization (NMF)\n",
    "- Latent Semantic Analysis (LSA)\n",
    "- Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models, similarities, matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "dim_red_choices = {\n",
    "    1: NMF,\n",
    "    2: TruncatedSVD,\n",
    "    3: models.LdaModel\n",
    "}\n",
    "\n",
    "def docs_with_topics(doc_topic,name,num_topics):\n",
    "    return pd.DataFrame(doc_topic.round(5), index = name, columns = [\"Topic \"+str(i) for i in range(num_topics)])\n",
    "\n",
    "@my_timer\n",
    "def topic_analysis(model, num_topics, vectorizer):\n",
    "    topic_word = pd.DataFrame(model.components_.round(3), index = [\"Topic \"+str(i) for i in range(num_topics)]\n",
    "                              ,columns = vectorizer.get_feature_names())\n",
    "    display_topics(model, vectorizer.get_feature_names(), 10)\n",
    "    return topic_word\n",
    "    \n",
    "@my_timer\n",
    "def dim_reduction_modeling(model_num, num_topics, doc_word,id2word=None):\n",
    "    \"\"\"\n",
    "    Select 1 for \n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model_num == 3:\n",
    "            return dim_red_choices[model_num](corpus=doc_word, num_topics=num_topics, id2word=id2word, passes=5)\n",
    "        else:\n",
    "            model = dim_red_choices[model_num](num_topics)\n",
    "            doc_topic = model.fit_transform(doc_word)\n",
    "            return model,doc_topic\n",
    "    except KeyError as K:\n",
    "        print(\"ERROR: Please select model numbers 1, 2, or 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_reduction_modeling ran in: 17.996272087097168 sec\n"
     ]
    }
   ],
   "source": [
    "num_topics = 7\n",
    "nmf, nmf_topic = dim_reduction_modeling(1,num_topics,doc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "one, night, get, bed, two, also, stayed, could, small, shower\n",
      "\n",
      "Topic  1\n",
      "city, station, metro, breakfast, walk, close, walking, center, minutes, distance\n",
      "\n",
      "Topic  2\n",
      "amazing, service, time, best, made, food, always, back, beautiful, make\n",
      "\n",
      "Topic  3\n",
      "nice, really, place, clean, rooms, big, breakfast, people, close, also\n",
      "\n",
      "Topic  4\n",
      "pool, bar, lovely, area, food, holiday, sun, plenty, entertainment, restaurant\n",
      "\n",
      "Topic  5\n",
      "beach, place, walk, white, away, restaurants, front, right, beautiful, water\n",
      "\n",
      "Topic  6\n",
      "stay, staff, friendly, helpful, recommend, location, would, clean, definitely, place\n",
      "topic_analysis ran in: 0.19394898414611816 sec\n"
     ]
    }
   ],
   "source": [
    "topic_word = topic_analysis(nmf, num_topics, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_results = docs_with_topics(nmf_topic,pos.hotel.to_list(),num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nmf, open(\"../results/models/nmf.pickle\",\"wb\"))\n",
    "pickle.dump(nmf_results, open(\"../results/models/nmf_results.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa, lsa_topic = dim_reduction_modeling(2,num_topics,doc_tfidf)\n",
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word2 = topic_analysis(lsa, num_topics, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_results=docs_with_topics(lsa_topic,pos.hotel.to_list(),num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = matutils.Sparse2Corpus(doc_tfidf.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in tfidf.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = dim_reduction_modeling(3,num_topics,corpus,id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using User Input Data\n",
    "\n",
    "Now that I have a working model, I can use custom input to match with the closest review in terms of cosine similarities. This will allow me to suggest a hotel for someone who's looking for one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Using one of the existing reviews:\n",
    "\n",
    "I want to make sure the model works correctly. If the user input is an exact match of one of the reviews, the highest cosine similarity should return that exact same review (since the cosine similarity of two identical text should be 1). I implement that here before I do a custom input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check = pos.content[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My girlfriend and I have traveled from Newfoundland, Canada and have been blown away by the resort, food and mostly the staff. From the moment we arrived we were tended to like royalty. We were given a great room close to all amenities. Whether it was breakfast , lunch , or supper the staff was polite and most helpful. The service on the beach from Jhoan Tav√°rez Jose Reyes Edwin Canarie and Johan Ventura is what has made our trip. We had rented the Bali beds every day and didn‚Äôt have to leave them. Everything we needed the guys made sure we had it. Will definitely be back !'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check2 = \"They moved but  luckily we found them! We recived  great  hospitality, red roses for valentines day. The room was, as always, very clean, spacious and well furnished. The place is very quite with a pretty patio for breakfast.  Close to most things  you need. Great Michela & Fabrizio! \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity_token = word_tokenize(clean_single(sanity_check))\n",
    "sanity_clean = clean_single(sanity_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my girlfriend and have traveled from newfoundland canada and have been blown away the resort food and mostly the staff from the moment arrived were tended like royalty were given great room close all amenities whether was breakfast lunch supper the staff was polite and most helpful the service the beach from jhoan tav rez jose reyes edwin canarie and johan ventura what has made our trip had rented the bali beds every day and didn have leave them everything needed the guys made sure had will definitely back \n"
     ]
    }
   ],
   "source": [
    "print(sanity_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_topic = nmf.transform(tfidf.transform([sanity_clean]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(cosine_similarity(sanity_topic, nmf_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My girlfriend and I have traveled from Newfoundland, Canada and have been blown away by the resort, food and mostly the staff. From the moment we arrived we were tended to like royalty. We were given a great room close to all amenities. Whether it was breakfast , lunch , or supper the staff was polite and most helpful. The service on the beach from Jhoan Tav√°rez Jose Reyes Edwin Canarie and Johan Ventura is what has made our trip. We had rented the Bali beds every day and didn‚Äôt have to leave them. Everything we needed the guys made sure we had it. Will definitely be back !'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_review = pos.iloc[index,:].content\n",
    "returned_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom User Input\n",
    "\n",
    "With the sanity check performing correctly, I can now implement the model using a custom text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@my_timer\n",
    "def predict(vectorizer, model, data_results):\n",
    "    description = input(\"Describe your dream vacation: \")\n",
    "    \n",
    "    # Preprocessing + Tokenizing\n",
    "    description = clean_single(description)\n",
    "#     desc_tokens = word_tokenize(description)\n",
    "    \n",
    "    # Vectorize and Tranform using model\n",
    "    user_matrix = vectorizer.transform([description])\n",
    "#     user_matrix = vectorizer.transform([desc_tokens])\n",
    "    user_topic = model.transform(user_matrix)\n",
    "    \n",
    "    cosines = cosine_similarity(user_topic, data_results)\n",
    "    \n",
    "    # Find max cosine similarity and print the original review content\n",
    "    idx = cosines[0].argsort()[-5:][::-1]\n",
    "\n",
    "    score = np.max(cosines[0])\n",
    "#     print(\"We suggest this hotel: \", reviews.iloc[index,:].hotel)\n",
    "#     print(\"Read what a guest wrote: \", reviews.iloc[index,:].content)\n",
    "    for i in range(len(idx)):\n",
    "        print(f\"Hotel #{i}: \", pos.iloc[idx[i],:].hotel)\n",
    "        print(f\"City #{i}\", pos.iloc[idx[i],:].city)\n",
    "        print(\"Read what a guest wrote: \", pos.iloc[idx[i],:].content)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe your dream vacation: I want to go to the beach\n",
      "Hotel #0:  White Beach de Boracay\n",
      "City #0 Boracay\n",
      "Read what a guest wrote:  Very beautiful beach. The purest water, a white sand, numerous cafes and shops in close proximity to the sea.\n",
      "Hotel #1:  Paamul Hotel\n",
      "City #1 Playa Del Carmen\n",
      "Read what a guest wrote:  Paamul is truly a little jewel in the Riviera Maya.  The hotel rooms are comfortable, spacious and very clean.  The views of the beach/ocean from the rooms are unbeatable.  The pool is awesome, overlooking the beach and the restaurant has delicious food.  Who can beat eating at a restaurant on the beach with the sea breeze blowing in your hair!  We can't wait to go back to Paamul!\n",
      "Hotel #2:  Ancora Punta Cana Private Residence, Yacht Club & Marina\n",
      "City #2 Punta Cana\n",
      "Read what a guest wrote:  We have visited there couple of times during our stay in Punta Cana and overall good beach to relax and swim. It is not that luxury beach or most attractive clean beach - but a decent beach to enjoy the breeze by the sea side.\n",
      "Hotel #3:  Ancora Punta Cana Private Residence, Yacht Club & Marina\n",
      "City #3 Punta Cana\n",
      "Read what a guest wrote:  We have visited there couple of times during our stay in Punta Cana and overall good beach to relax and swim. It is not that luxury beach or most attractive clean beach - but a decent beach to enjoy the breeze by the sea side.\n",
      "Hotel #4:  Excellence El Carmen\n",
      "City #4 Punta Cana\n",
      "Read what a guest wrote:  Great service..especially Antonio at the beach bar, Carmen serving drinks at the Excellence Club beach area and our sommelier at Chez Isabelle!! Relaxed, elegant and easy to have fun at this beautiful seaside resort\n",
      "predict ran in: 4.239999055862427 sec\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-dca2a5f734a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmf_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "matrix, indices= predict(tfidf, nmf, nmf_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "hello"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.582px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
